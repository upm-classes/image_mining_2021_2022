{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_image_mining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/upm-classes/image_mining_2021_2022/blob/main/classification_image_mining.ipynb)"
      ],
      "metadata": {
        "id": "2wG6KfjR7NL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "WtJximVx5Oap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfSgLSSXYf3h"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = 'rock_paper_scissors'\n",
        "\n",
        "image_train, label_train = tfds.as_numpy(tfds.load(\n",
        "    ds_name,\n",
        "    split='train',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True,\n",
        "))\n",
        "image_test, label_test = tfds.as_numpy(tfds.load(\n",
        "    ds_name,\n",
        "    split='test',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True, \n",
        "))"
      ],
      "metadata": {
        "id": "sD3fLXHpZRuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number images in train set: {image_train.shape[0]}')\n",
        "print(f'Number images in test set: {image_test.shape[0]}')\n",
        "print(f'Labels in train set: {np.unique(label_train)}')\n",
        "print(f'Labels in test set: {np.unique(label_test)}')"
      ],
      "metadata": {
        "id": "u8w5JkNAZ_1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "B2v2rZ1J5oF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(image_train.shape[0]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    \n",
        "    im = image_train[rand_samples[i]]\n",
        "    label = label_train[rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f\"Label: {label}\")\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vzo0TxRAZuaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(image_test.shape[0]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    \n",
        "    im = image_test[rand_samples[i]]\n",
        "    label = label_test[rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f\"Label: {label}\")\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mqBD_5mkm0PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Information about classes in train set:')\n",
        "\n",
        "classes = np.unique(label_train)\n",
        "description = np.array([(c, np.sum(label_train == c)) for c in classes])\n",
        "\n",
        "for desc in description:\n",
        "    print('Class: {}, number of samples: {}'.format(desc[0], desc[1]))\n",
        "\n",
        "plt.bar(description[:,0], description[:,1].astype(int))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A9rUTNOlm6vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Information about classes in test set:')\n",
        "\n",
        "classes = np.unique(label_test)\n",
        "description = np.array([(c, np.sum(label_test == c)) for c in classes])\n",
        "\n",
        "for desc in description:\n",
        "    print('Class: {}, number of samples: {}'.format(desc[0], desc[1]))\n",
        "\n",
        "plt.bar(description[:,0], description[:,1].astype(int))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F8AldfggiSW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification with histogram as a feature"
      ],
      "metadata": {
        "id": "XAIUiTm6x4Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from joblib import dump, load\n",
        "import os"
      ],
      "metadata": {
        "id": "8zoPjU1foy_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "\n",
        "x_train = image_train.astype(np.uint8)\n",
        "\n",
        "x_train = np.array([np.concatenate([cv2.calcHist(x_train[i],[0],None,[256],[0,256]), \n",
        "                cv2.calcHist(x_train[i],[1],None,[256],[0,256]),\n",
        "                cv2.calcHist(x_train[i],[2],None,[256],[0,256])]) \n",
        "for i in range(x_train.shape[0])])\n",
        "x_train = np.squeeze(x_train)\n",
        "\n",
        "max_value = np.max(x_train)\n",
        "x_train = x_train / max_value\n",
        "\n",
        "# Test set\n",
        "x_test = image_test.astype(np.uint8)\n",
        "\n",
        "x_test = np.array([np.concatenate([cv2.calcHist(x_test[i],[0],None,[256],[0,256]), \n",
        "                cv2.calcHist(x_test[i],[1],None,[256],[0,256]),\n",
        "                cv2.calcHist(x_test[i],[2],None,[256],[0,256])]) \n",
        "for i in range(x_test.shape[0])])\n",
        "x_test = np.squeeze(x_test)\n",
        "\n",
        "x_test = x_test / max_value\n",
        "\n",
        "print(f'Size of the train set: {x_train.shape}')\n",
        "print(f'Size of the test set: {x_test.shape}')\n",
        "\n",
        "plt.plot(x_train[0])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x_test[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sduPAF3TrASZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'svm_model_1_pixels.joblib'\n",
        "\n",
        "model = svm.SVC() # You can set the parameters\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "  model.fit(x_train, label_train) # Fitting the model\n",
        "  dump(model, model_name) # saving model\n",
        "else:\n",
        "  model = load(model_name) # loading model"
      ],
      "metadata": {
        "id": "ypb8XJR6ps--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_train = model.predict(x_train)\n",
        "\n",
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_train, predicted_train)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_train, predicted_train)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8_2zd_jZSNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_test = model.predict(x_test)"
      ],
      "metadata": {
        "id": "phFjAXWqqpjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some predictions\n",
        "\n",
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(x_test.shape[0]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    im = image_test[rand_samples[i]]\n",
        "    label = label_test[rand_samples[i]]\n",
        "    predicted_label = predicted_test[rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f\"Label: {label} -- Prediction: {predicted_label}\")\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z9WBAG4Fw7Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_test, predicted_test)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_test, predicted_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tkjlc0krxx1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification using deep features"
      ],
      "metadata": {
        "id": "ZT-dQmEvyX94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "H02GdMUL0wdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt](https://1.bp.blogspot.com/-nJlr9zzycPs/XOfawrPqhUI/AAAAAAAAADQ/t2WtEQDrboMPlHgvDEJsk48rkDzC_KGaACLcBGAs/s1600/resnet50.JPG \"Resnet-50\")"
      ],
      "metadata": {
        "id": "-UDq_FlqVrxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights=\"imagenet\", include_top=False)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "okd1v75R1JPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "\n",
        "for i in tqdm(range(image_train.shape[0])):\n",
        "  im = image_train[i].astype(np.uint8)\n",
        "  im = cv2.resize(im, (224, 224))\n",
        "  im = preprocess_input(im)\n",
        "  features = model.predict(np.expand_dims(im, axis=0)) # size 1 x 7 x 7 x 2048\n",
        "  features = features.reshape((features.shape[1] * features.shape[2] * \n",
        "                               features.shape[3]))\n",
        "\n",
        "  x_train.append(features)\n",
        "x_train = np.array(x_train)\n",
        "\n",
        "x_test = []\n",
        "\n",
        "for i in tqdm(range(image_test.shape[0])):\n",
        "  im = image_test[i].astype(np.uint8)\n",
        "  im = cv2.resize(im, (224, 224))\n",
        "  im = preprocess_input(im)\n",
        "  features = model.predict(np.expand_dims(im, axis=0)) # size 1 x 7 x 7 x 2048\n",
        "  features = features.reshape((features.shape[1] * features.shape[2] * \n",
        "                               features.shape[3])) #100352\n",
        "\n",
        "  x_test.append(features)\n",
        "x_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "YPcvrFrcyZ2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = image_test[i].astype(np.uint8)\n",
        "im = cv2.resize(im, (224, 224))\n",
        "im = preprocess_input(im)"
      ],
      "metadata": {
        "id": "j4SW_mfZFN_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "ax1.imshow(image_test[i].astype(np.uint8))\n",
        "ax2.imshow((im + np.abs(np.min(im)))/np.max(im  + np.abs(np.min(im)))) # range [0,1]\n",
        "plt.show()\n",
        "\n",
        "features = model.predict(np.expand_dims(im, axis=0))\n",
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(features.shape[3]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    img = features[0, :, :, rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f'Feature {rand_samples[i]}')\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z0B2WCHhAppS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'svm_model_2_pixels.joblib'\n",
        "\n",
        "model = svm.SVC() # You can set the parameters\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "  model.fit(x_train, label_train) # Fitting the model\n",
        "  dump(model, model_name) # saving model\n",
        "else:\n",
        "  model = load(model_name) # loading model"
      ],
      "metadata": {
        "id": "jCIjMES1-kKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_train = model.predict(x_train)\n",
        "\n",
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_train, predicted_train)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_train, predicted_train)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5FUfunmPSj5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(x_test)"
      ],
      "metadata": {
        "id": "0bdM1cSE-gNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(x_test.shape[0]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    \n",
        "    im = image_test[rand_samples[i]]\n",
        "    label = label_test[rand_samples[i]]\n",
        "    predicted_label = predicted[rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f\"Label: {label} -- Prediction: {predicted_label}\")\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UgTxtehT15E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_test, predicted)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_test, predicted)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BpjOpMdP-8HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification using Deep features with PCA"
      ],
      "metadata": {
        "id": "-CInwB-qCEbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA is a dimensionality reduction method that identifies important relationships in data, transforms existing data based on these relationships, and then quantifies the importance of these relationships so that we can keep the most important ones and drop the others (correlated data). "
      ],
      "metadata": {
        "id": "xeZMMVIXHgzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "PKAfyuMfG-oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(x_train)\n",
        "\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "selected_components = np.where(cumsum >= 0.95)[0][0] + 1\n",
        "\n",
        "print(f'Explained variance: {cumsum[selected_components]} by {selected_components} components')"
      ],
      "metadata": {
        "id": "wZXTW58LCDlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=selected_components)\n",
        "pca.fit(x_train)\n",
        "\n",
        "print(f'Explained variance: {np.sum(pca.explained_variance_ratio_)} by {selected_components} components')"
      ],
      "metadata": {
        "id": "ErnNj_6XIMTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pca = pca.transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)"
      ],
      "metadata": {
        "id": "Teu8KXi5Ip78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'svm_model_3_pixels.joblib'\n",
        "\n",
        "model = svm.SVC() # You can set the parameters\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "  model.fit(x_train_pca, label_train) # Fitting the model\n",
        "  dump(model, model_name) # saving model\n",
        "else:\n",
        "  model = load(model_name) # loading model"
      ],
      "metadata": {
        "id": "V_b_9HROLQ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_train = model.predict(x_train_pca)\n",
        "\n",
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_train, predicted_train)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_train, predicted_train)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZF6ENPcySmJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(x_test_pca)"
      ],
      "metadata": {
        "id": "f8KrrzTQLdku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10\n",
        "\n",
        "rand_samples = np.random.choice(np.arange(x_test.shape[0]), num_samples)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 8))\n",
        "for i in range(num_samples):\n",
        "    \n",
        "    im = image_test[rand_samples[i]]\n",
        "    label = label_test[rand_samples[i]]\n",
        "    predicted_label = predicted[rand_samples[i]]\n",
        "    ax = fig.add_subplot(2, 5, i+1)\n",
        "    ax.set_title(f\"Label: {label} -- Prediction: {predicted_label}\")\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PsV9z9h7LnHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification report for classifier\")\n",
        "print(f\"{classification_report(label_test, predicted)}\")\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(label_test, predicted)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cPeeijMJLsv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiying by training a pretrained neural network"
      ],
      "metadata": {
        "id": "NWPxS9d3SsYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from skimage.transform import resize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pickle import dump"
      ],
      "metadata": {
        "id": "JnZYjK_sW1s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "8x9lh-Vd48oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_name = 'rock_paper_scissors'\n",
        "\n",
        "image_train, label_train = tfds.as_numpy(tfds.load(\n",
        "    ds_name,\n",
        "    split='train',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True,\n",
        "))\n",
        "image_test, label_test = tfds.as_numpy(tfds.load(\n",
        "    ds_name,\n",
        "    split='test',\n",
        "    batch_size=-1,\n",
        "    as_supervised=True, \n",
        "))"
      ],
      "metadata": {
        "id": "rrX4kmNsTGh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(np.arange(image_train.shape[0]),\n",
        "                                                  label_train, \n",
        "                                                  test_size=0.20, \n",
        "                                                  random_state=23)\n",
        "\n",
        "x_train = image_train[x_train, ...]\n",
        "x_val = image_train[x_val, ...]\n",
        "x_test = image_test\n",
        "y_test = label_test\n",
        "\n",
        "print('Training set shape: {}'.format(x_train.shape))\n",
        "print('Validation set shape: {}'.format(x_val.shape))\n",
        "print('Test set shape: {}'.format(x_test.shape))"
      ],
      "metadata": {
        "id": "XyO6xIFNsPq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train[:280]\n",
        "y_train = y_train[:280]\n",
        "\n",
        "x_val = x_val[:280]\n",
        "y_val = y_val[:280]"
      ],
      "metadata": {
        "id": "lxKchvTD0Nsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "mlDPFcfAvtwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resizing images to (224, 224) and rescale to [0,1] range\n",
        "x_train = np.array([resize(x_train[i, :, :, :], (224, 224)) for i in range(x_train.shape[0])])\n",
        "x_val = np.array([resize(x_val[i, :, :, :], (224, 224)) for i in range(x_val.shape[0])])\n",
        "x_test = np.array([resize(x_test[i, :, :, :], (224, 224)) for i in range(x_test.shape[0])])"
      ],
      "metadata": {
        "id": "bhibh2envr_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoder labels\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y_train.reshape(-1, 1))\n",
        "\n",
        "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_val = enc.transform(y_val.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "oN8FzxuI120v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "KlfcYYlN13yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "ds_train = ds_train.batch(56) # batch size\n",
        "ds_val = ds_val.batch(56)"
      ],
      "metadata": {
        "id": "iDs6DuqNoo7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "tLWMVhzC40fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 3\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "base_model = ResNet50(weights=\"imagenet\", \n",
        "                      input_shape=input_shape, \n",
        "                      include_top=False)\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "x = base_model(inputs, training=True)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "outputs = Dense(n_classes, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RwaOA1HiWZZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to recompile our model\n",
        "model.compile(optimizer=Adam(1e-5),  # 1e-5 learning rate\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=[CategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "-lHsJHnRWX61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "8BdinvXU431U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=2),\n",
        "    ModelCheckpoint(filepath='model.{epoch:04d}-{val_loss:.8f}.h5'),\n",
        "    CSVLogger('training.log'),\n",
        "]\n",
        "\n",
        "model.fit(ds_train, validation_data=ds_val, epochs=num_epochs, \n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "id": "rBAw4sywd7ox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}